# Technical Architecture

This document provides detailed technical architecture for the Pro Forma Analytics Tool.

## üèóÔ∏è System Architecture

### High-Level Design Principles

1. **Data-Driven**: All forecasts based on historical data, not subjective estimates
2. **Modular**: Clear separation between data, forecasting, and presentation layers  
3. **Scalable**: Designed to handle additional metrics and geographies
4. **Maintainable**: Simple, clean interfaces with comprehensive documentation
5. **Testable**: Each component can be validated independently

### Component Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           PRESENTATION LAYER                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Web Interface  ‚îÇ  ‚îÇ   CLI Tools     ‚îÇ  ‚îÇ  Report Engine  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Dashboards    ‚îÇ  ‚îÇ ‚Ä¢ data_manager  ‚îÇ  ‚îÇ ‚Ä¢ PDF Export    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Scenario UI   ‚îÇ  ‚îÇ ‚Ä¢ Verification  ‚îÇ  ‚îÇ ‚Ä¢ Excel Export  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Charts/Graphs ‚îÇ  ‚îÇ ‚Ä¢ Data Ops      ‚îÇ  ‚îÇ ‚Ä¢ Custom Views  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ             ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          BUSINESS LOGIC LAYER                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ARIMA Forecasts ‚îÇ  ‚îÇ Monte Carlo Sim ‚îÇ  ‚îÇ Risk Analysis   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Time Series   ‚îÇ  ‚îÇ ‚Ä¢ Correlation   ‚îÇ  ‚îÇ ‚Ä¢ Sensitivity   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Auto Selection‚îÇ  ‚îÇ ‚Ä¢ Scenarios     ‚îÇ  ‚îÇ ‚Ä¢ Stress Tests  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Validation    ‚îÇ  ‚îÇ ‚Ä¢ Percentiles   ‚îÇ  ‚îÇ ‚Ä¢ Comparisons   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ             ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            DATA LAYER                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Database Manager‚îÇ  ‚îÇ Data Collection ‚îÇ  ‚îÇ API Integration ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ SQLite DBs    ‚îÇ  ‚îÇ ‚Ä¢ Validation    ‚îÇ  ‚îÇ ‚Ä¢ FRED API      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Schema Mgmt   ‚îÇ  ‚îÇ ‚Ä¢ Transformation‚îÇ  ‚îÇ ‚Ä¢ Future APIs   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Query Engine  ‚îÇ  ‚îÇ ‚Ä¢ Quality Check ‚îÇ  ‚îÇ ‚Ä¢ Rate Limiting ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üíæ Data Architecture

### Database Design Philosophy

**Normalized by Function**: Each database serves a specific analytical purpose
- **market_data.db**: Financial market conditions
- **property_data.db**: Real estate specific metrics  
- **economic_data.db**: Regional economic indicators
- **forecast_cache.db**: Computed forecasts and simulations

### Entity Relationship Model

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   market_data   ‚îÇ     ‚îÇ  property_data  ‚îÇ     ‚îÇ  economic_data  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ interest_rates  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇrental_market_data‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇproperty_growth  ‚îÇ
‚îÇ cap_rates       ‚îÇ     ‚îÇ operating_expenses‚îÇ    ‚îÇlending_requirements‚îÇ
‚îÇ economic_indicators‚îÇ   ‚îÇ property_tax_data‚îÇ    ‚îÇregional_econ_indicators‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ forecast_cache  ‚îÇ
                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                    ‚îÇ arima_forecasts ‚îÇ
                    ‚îÇ parameter_correlations‚îÇ
                    ‚îÇ monte_carlo_results‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Schema Design Patterns

#### Temporal Data Pattern
All metric tables follow consistent temporal structure:
```sql
CREATE TABLE metric_table (
    date DATE NOT NULL,                    -- Annual data points
    [metric_specific_fields],              -- Varies by table
    value REAL NOT NULL,                   -- Standardized value field
    geographic_code TEXT NOT NULL,        -- MSA/FIPS code
    data_source TEXT NOT NULL,            -- Traceability
    PRIMARY KEY(date, [key_fields], geographic_code)
);
```

#### Geographic Normalization
- **MSA Codes**: 5-digit Census Bureau codes for metropolitan areas
- **FIPS Codes**: County-level Federal Information Processing Standards
- **Consistent Naming**: Standardized geographic identifiers across all tables

#### Data Quality Assurance
- **Primary Keys**: Prevent duplicate records
- **NOT NULL Constraints**: Ensure data completeness
- **Type Validation**: Proper data types for all fields
- **Source Tracking**: All data includes source attribution

## üîÑ Data Flow Architecture

### Collection Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   External  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Extract   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Transform   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Load     ‚îÇ
‚îÇ   Sources   ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îÇ             ‚îÇ    ‚îÇ ‚Ä¢ API Calls ‚îÇ    ‚îÇ ‚Ä¢ Validate  ‚îÇ    ‚îÇ ‚Ä¢ Insert    ‚îÇ
‚îÇ ‚Ä¢ FRED API  ‚îÇ    ‚îÇ ‚Ä¢ Mock Data ‚îÇ    ‚îÇ ‚Ä¢ Convert   ‚îÇ    ‚îÇ ‚Ä¢ Update    ‚îÇ
‚îÇ ‚Ä¢ Future    ‚îÇ    ‚îÇ ‚Ä¢ Files     ‚îÇ    ‚îÇ ‚Ä¢ Clean     ‚îÇ    ‚îÇ ‚Ä¢ Verify    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Processing Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Historical  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    ARIMA    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Monte Carlo ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Output    ‚îÇ
‚îÇ    Data     ‚îÇ    ‚îÇ Forecasting ‚îÇ    ‚îÇ Simulation  ‚îÇ    ‚îÇ             ‚îÇ
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ ‚Ä¢ Reports   ‚îÇ
‚îÇ ‚Ä¢ Clean     ‚îÇ    ‚îÇ ‚Ä¢ Model Fit ‚îÇ    ‚îÇ ‚Ä¢ Scenarios ‚îÇ    ‚îÇ ‚Ä¢ Charts    ‚îÇ
‚îÇ ‚Ä¢ Validated ‚îÇ    ‚îÇ ‚Ä¢ Forecast  ‚îÇ    ‚îÇ ‚Ä¢ Risk Calc ‚îÇ    ‚îÇ ‚Ä¢ Export    ‚îÇ
‚îÇ ‚Ä¢ Complete  ‚îÇ    ‚îÇ ‚Ä¢ Cache     ‚îÇ    ‚îÇ ‚Ä¢ Cache     ‚îÇ    ‚îÇ ‚Ä¢ API       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üß© Component Architecture

### Core Components

#### 1. Database Manager (`data/databases/database_manager.py`)
**Responsibility**: Database operations and connection management

```python
class DatabaseManager:
    # Connection management
    def get_connection(db_name: str) -> Connection
    def initialize_databases() -> None
    
    # Data operations  
    def insert_data(db_name: str, table: str, data: Union[Dict, List]) -> int
    def query_data(db_name: str, query: str, params: tuple) -> List[Dict]
    
    # Parameter-specific methods
    def get_parameter_data(parameter: str, geography: str) -> List[Dict]
    def save_forecast(parameter: str, geography: str, results: Dict) -> None
    def get_cached_forecast(parameter: str, geography: str) -> Optional[Dict]
```

#### 2. Data Collector (`collect_simplified_data.py`)
**Responsibility**: Historical data collection and validation

```python
class SimplifiedDataCollector:
    # Metric-specific collection
    def collect_interest_rates() -> Dict[str, Any]
    def collect_vacancy_rates() -> Dict[str, Any]
    def collect_rent_growth() -> Dict[str, Any]
    # ... other metrics
    
    # Orchestration
    def run_full_collection() -> Dict[str, Any]
    
    # Utilities
    def _generate_time_series(parameter: str, config: Dict) -> List[Dict]
```

#### 3. Configuration Management (`config/`)

**Geography Configuration** (`geography.py`):
```python
@dataclass
class GeographicRegion:
    name: str
    msa_code: Optional[str]
    fips_code: Optional[str]
    state: Optional[str]

class GeographyManager:
    def list_regions() -> List[str]
    def get_region(name: str) -> Optional[GeographicRegion]
```

**Parameter Configuration** (`parameters.py`):
```python
@dataclass
class ParameterDefinition:
    name: str
    parameter_type: ParameterType
    description: str
    unit: str
    typical_range: Tuple[float, float]
    data_sources: List[str]
    fred_series: Optional[str]
```

### Interface Contracts

#### Data Collection Interface
```python
def collect_metric(metric_name: str, geography: str) -> CollectionResult:
    """
    Standard interface for metric collection.
    
    Returns:
        CollectionResult with records_inserted, errors, metadata
    """
```

#### Forecasting Interface (Future)
```python
def generate_forecast(parameter: str, geography: str, 
                     horizon_years: int) -> ForecastResult:
    """
    Standard interface for ARIMA forecasting.
    
    Returns:
        ForecastResult with values, confidence_intervals, model_info
    """
```

#### Simulation Interface (Future)
```python
def run_monte_carlo(parameters: List[str], geography: str,
                   num_simulations: int) -> SimulationResult:
    """
    Standard interface for Monte Carlo simulation.
    
    Returns:
        SimulationResult with scenarios, statistics, risk_metrics
    """
```

## üîß Technology Stack

### Current Implementation
- **Language**: Python 3.8+
- **Database**: SQLite 3
- **Data Processing**: pandas, numpy
- **API Integration**: requests
- **Date/Time**: datetime, pandas date handling

### Future Additions (Phase 2+)
- **Time Series**: statsmodels (ARIMA), scipy
- **Simulation**: numpy.random, scipy.stats
- **Visualization**: plotly, matplotlib
- **Web Framework**: FastAPI or Flask
- **Testing**: pytest, unittest

## üìä Performance Considerations

### Database Performance
- **Indexing Strategy**: Indexes on date, geographic_code, and metric identifiers
- **Query Optimization**: Parameterized queries with proper type handling
- **Connection Pooling**: Context managers for efficient connection handling

### Memory Management
- **Streaming**: Large datasets processed in chunks
- **Caching**: Computed forecasts cached to avoid recomputation
- **Lazy Loading**: Data loaded only when needed

### Scalability Design
- **Horizontal Scaling**: Each MSA can be processed independently
- **Vertical Scaling**: Additional metrics added without architectural changes
- **Caching Layer**: Forecast results cached for performance

## üõ°Ô∏è Security & Data Integrity

### Data Validation
- **Schema Enforcement**: Database constraints prevent invalid data
- **Range Validation**: Metric values validated against reasonable ranges
- **Source Verification**: All data includes source attribution
- **Completeness Checks**: Automated verification of data coverage

### Error Handling
- **Graceful Degradation**: System continues operating with partial data
- **Comprehensive Logging**: All operations logged for debugging
- **Rollback Capability**: Failed operations don't corrupt existing data
- **Validation Gates**: Multi-level validation prevents bad data propagation

### API Security (Future)
- **Rate Limiting**: Prevent API abuse
- **Authentication**: Secure access to forecasting endpoints
- **Input Sanitization**: Prevent injection attacks
- **Output Validation**: Ensure response data integrity

## üîÑ Development Patterns

### Configuration Management
- **Environment-Specific**: Different configs for dev/test/prod
- **Centralized**: All configuration in `config/` directory
- **Type-Safe**: Dataclasses with type hints for configuration
- **Validation**: Configuration validated at startup

### Error Handling Pattern
```python
try:
    result = operation()
    return {'success': True, 'data': result, 'errors': []}
except SpecificException as e:
    logger.error(f"Specific error in {operation}: {e}")
    return {'success': False, 'data': None, 'errors': [str(e)]}
except Exception as e:
    logger.error(f"Unexpected error in {operation}: {e}")
    return {'success': False, 'data': None, 'errors': [str(e)]}
```

### Testing Strategy
- **Unit Tests**: Individual function testing
- **Integration Tests**: Database and API integration
- **Data Validation Tests**: Data quality and completeness
- **End-to-End Tests**: Full workflow validation

This architecture provides a solid foundation for the current system and clear extension points for future development phases.